% Kompiuterijos katedros šablonas
% Template of Department of Computer Science II
% Versija 1.0 2015 m. kovas [ March, 2015]

\documentclass[a4paper,12pt,fleqn]{article}
\input{allPacks}

\newtoggle{inLithuanian}
 %If the report is in Lithuanian, it is set to true; otherwise, change to false
\settoggle{inLithuanian}{false}

%create file preface.tex for the preface text
%if preface is needed set to true
\newtoggle{needPreface}
\settoggle{needPreface}{false}

\newtoggle{signaturesOnTitlePage}
\settoggle{signaturesOnTitlePage}{true}

\input{macros}

\begin{document}
% #1 -report type, #2 - title, #3-7 students, #8 - supervisor
\depttitlepage{Bachelors Thesis}{Implementation of application for visualization of regularities and randomness in data}{Audrius Baranauskas}
{}{}{}{}% students 2-5
{Ph. D. Tadas Meškauskas}

\tableofcontents


%keywords and notations if needed
\sectionWithoutNumber{Keywords}{keywords}{Pateikiamas terminų sąrašas (jei reikia)}

%both abstracts
\bothabstracts{\input{abstract}}%tex-file of abstract in original language
{Aplikacijos kūrimas dėsningumų ir atsitiktinumų duomenyse vizualizavimui} %if work is in LT this title should be in English
{\input{abstractEN}}%tex-file of abstract in other language


%Introduction section: label is sec:intro
\sectionWithoutNumber{\keyWordIntroduction}{intro}
\input{introduction.tex}

\newpage
%=============================================================
%========================The main part========================
%=============================================================


%=================================Data randomness and regularities
\section{Data randomness and regularities}
This section covers what is the expected input and output of data analysis.
It will explore a method for identifying data characteristics and its limitations.
Finally it will dive deeper into innerworkings of the given tool used for this task.


%=================================Data randomness and regularities
\subsection{Signal data}
A signal is a function that conveys information about the behaviour of a system or attributes of some phenomenon \cite{priemer1990introductory}.
For example, measuring the time taken between a weight-driven
pendulum clock's ticks produces a signal.
This hypthetical singal would consist of a series of numbers identifying how long each pendulum swing took.
In this case such a signal could be expressed as a one dimensional stream of data.
For the scope of this paper every singal we analyze will be a one dimensional series of numbers.
When refering to singals we will use terms \textbf{signal} and \textbf{data} interchangeably.

\subsection{Recurrence plot}
To tackle the problem of identifying randomness and regularities in signals a \textbf{recurrence plot} can be utilized.
A recurrence plot is a an illustration that can help determine the non-triviality of a given data series.
It visualizates when a given signal repeats for each moment in a time series.

Given a \code{data} array of deciman numbers, the very primitive python implementation of the algorithm would look similar to this:
\begin{lstlisting}[caption={Primitive recurrence plot algorithm}\label{lst:rp-primitive}]
  def generate_recurrence_plot(data:list, r:int):
    recurrences = []
    
    for i in range(len(data)):
      for j in range(len(data)):
        if (abs(data[i] - data[j]) <= r):
          recurrences.append([i, j])

    return recurrences
\end{lstlisting}
The example above defines a method \code{generate\_recurrence\_plot} that takes in parameters \code{data} and \code{r}, of types \emph{list} and \emph{int} respectively.
The method compares each element in \code{data} to every element including itself.
If the difference of these elements is no larger than a given threshold \code{r} - they are considered similar and their index positions are added to the recurrences array.
The method then returns an array of index pairs when data values were similar.
These pairs can be represented as pixel possitions in an image and plotted to form a recurrence plot.

\begin{figure*}[ht!]
  \subfloat[\label{fig:theory_sin_data}]{
    \includegraphics[width=0.3\textwidth]{assets/theory_graph_sin.png}}
  \hspace{\fill}
  \subfloat[\label{fig:theory_sin_rp_sm} ]{
    \includegraphics[width=0.3\textwidth]{assets/theory_rp_sin_sm.png}}
  \hspace{\fill}
  \subfloat[\label{fig:theory_sin_rp_lg}]{
    \includegraphics[width=0.3\textwidth]{assets/theory_rp_sin_lg.png}}
  \caption{\label{fig:theory_sin}(a) Sine wave data; (b) Recurrence plot D=1, d=1, r=0.0017; (c) Recurrence plot D=1, d=1, r=0.06}
\end{figure*}
In figure~\ref{fig:theory_sin} we can see a sine wave data on the left (a). 
The recurrence plot in the middle (b) is generated with a small value for \code{r} and produces a pattern with cross signs.
Meanwhile the graph on the right (c) has a higher \code{r} value and displays a grid pattern.
Recurrence plot (c) has noticably more black pixels.
From observations in figure~\ref{fig:theory_sin}, we can conclude that the value for \code{r} ir proportional to the amount of similarities found when generating a recurrence plot.

\subsection{Recurrence plot parameters}
Now that we know how a basic version of the algorithm behaves we can dive deeper into the recurrence plot algorithm.
It is important to note that not all signal have such predictable patterns.
Measuring the similarity of two values helps us understand where data \emph{values} are similar.
However, two sequential signal values being similar does indicate that the following values are similar as well.
A better way to approach detecting similarities is comparing signal \emph{states} instead of \emph{values}.

Signal state is a collection of signal values commonly represented as a vector.
A linear signal's state can be represented as a pair of two consecutive signal values.
The number of consecutive values that make up a signal state is arbitraty and can be increased to tripplets, quadruplets, $D$-plets.
For example, recurrence plots generated in figure~\ref{fig:theory_sin} used $D$ a parameter of $1$, therefore it is also correct state that the algorithm in listing~\ref{lst:rp-primitive} was used to compare one dimensional vectors.
For example, given a signal of length ${N}$, and a $D$ parameter, one can divide the signal sequence into a list of signal state vectors.
\[
  y_0=(f_0,f_1,...,f_{D-1}) ,\quad y_1=(f_1,f_2,...,f_{D}) ,\quad ...,\quad y_{N-D}=
  (f_{N-(D-1)-1},f_{N-(D-0)-1},...,f_{N-1})
\]
It is also worth metioning that a signal state not necessarily contain sequential values.
Signal values can also be have a delay step $d$.
The delay step indicates that only every $d$-th element is to be used to compose a given signal state.
This translates into the following series of elements, given a signal length of $N$, $D$ and $d$ parameters.
\[
  y_0=(f_0,f_{d},...,f_{(D-1)*d}) ,\quad y_1=(f_1,f_{d+1},...,f_{D*d}) , \quad \longrightarrow
\]
\[
  ...,\quad y_{N-(D-1)*d}=(f_{N-(D-1)*d},f_{N-(D-0)*d},...,f_{N-1})  
\]
It is apparent that the number of associated signal states decreases in relation to $D$ and $d$. 
The total number of signal states is denoted with $M$.
From the expression above we can extrapolate that the $M$ is calculated by using the following expression.
\[
  M = N-(D-1)*d
\]
We can conclusively state for a given signal $Y$ of length $N$, the generated recurrence plot is always of size $M^2$.

\subsection{Comparing signal states}
\label{sec:comparing-signal-states}
Now that we have familiarize with recurrence plot parameters let us go back to out primitive implementation in listing~\ref{lst:rp-primitive}.
We are no longer comparing values, but rather - vectors.

A distance between two vectors $v_i$ and $v_j$ is denoted as $||v_i - v_j||$.
We can assign this vector distance to a $D$ - dimensional point $p = (p_1, p_2, ..., p_D)$.

The most common way of comparing vector length is by utilizing the \emph{Euclidean metric} also known as the $L_2$ \emph{norm}.
$L_2$ norm calculates the distance between a vector in a $D$ - dimensional space and the start of the coordinate plane.
This norm can be derrived by using the Pythagorean theorem:
\[
  ||v|| = \sqrt{v_1^2 + v_2^2 + v_3^2 + ... + v_D^2}
\]
Alternative solutions for calculating a vector distance are the Manhattan norm
\[
  ||v|| = |v_1| + |v_2| + |v_3| + ... + |v_D|
\]
and the Maximum norm.
\[
  ||v|| = max(|v_1|,|v_2|,|v_3|.+ ... +,|v_D|)
\]
From a computational perspective it becomes quite apparent that the Maximum norm requires the least effort.
\begin{figure*}[ht!]
  \subfloat[\label{fig:dji2015}]{
    \includegraphics[width=0.3\textwidth]{assets/DJI2015-2020_scaled.png}}
  \hspace{\fill}
  \subfloat[\label{fig:theory_rp_euclidean} ]{
    \includegraphics[width=0.3\textwidth]{assets/theory_rp_euclidean.png}}
  \hspace{\fill}
  \subfloat[\label{fig:theory_rp_maximum}]{
    \includegraphics[width=0.3\textwidth]{assets/theory_rp_maximum.png}}
  \caption{\label{fig:theory_dji}(a) The Dow Jones Industrial Average adjusted for inflation 2015-2020; (b) Recurrence plot using the Euclidean norm D=4, d=2, r=842, T=3s; (c) Recurrence plot using the Euclidean norm D=4, d=2, r=1969, T=0.5s; Source: yahoo-finance~\cite{yahoo-finance}}
\end{figure*}
For the scope of this paper we have compared the performance characteristics of the Euclidean and the Maximum norms.
Figure~\ref{fig:theory_dji}, graph on the left~\ref{fig:dji2015} illustrates stock price fluctuations of the Dow Jones Industrial average.
Recurrence plot in the middle~\ref{fig:theory_rp_euclidean} is generated using the Euclidean norm, while plot on the right~\ref{fig:theory_rp_maximum} utilizes the Maximum norm.
Only a miniscule differences can be observed in the generated plots.
However, as capture indicates, the Maximum norm performed about 6 times faster than the Euclidean, taking 0.5 and 3 seconds to complete respectively.


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Performance improvements}
One giant leap in performance was the utilization of the Maximum norm instead of the Euclidean norm as documented in section~\ref{sec:comparing-signal-states}.
The recurrence plot algorithm can be further optimised by only calculating one half of the recurrence plot.
Refering back to listing~\ref{lst:rp-primitive}, we could make simple code modification to the looping system as shown in listing~\ref{lst:rp-looping}.
\begin{lstlisting}[caption={Improved looping system}\label{lst:rp-looping}]
for i in range(len(data)):
  for j in range(i, len(data)):
    #Signal state comparison
\end{lstlisting}
Note that the second level loop now iterates an ever decreasing number of times.
If plotted, the recurrence plot would only have one half if the image divided by the symetry line.
This can be easy overcome by populating the similarities array with the same data, just switched positions of indices.
This effectively reduces the processing time in half. 

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Calculating the pixel percentage}
A key characteristic of a recurrence graph is the diagonal line of symetry spanning across the image.
This line is always present because the algorithm iterates in a nested loop.
Looking back at listing~\ref{lst:rp-primitive} we can identify that when the first level loop iterator \code{i} is equal to the second level loop iterator \code{j} - the algorithm compares a distance between the same sygnal states as \code{data[i]} and \code{data[j]} use the identical index.
Regardless of the vector $D$ dimensionality and the norm used to find the distance - it always remains zero.
As $r$ has to be a positive number, we can conclude that a distance of zero is always less than the threshold.
Therefore in a given image of size $M$ the similarities array returned by a recurrence plot algorithm always includes similarities at positions $(i, j)$, when $i = j$.

Consequently, calculating pixel percentage of a recurrence plot requires us to exclude the diagonal line.
The total number of pixels in a recurrence plot is $M^2$.
A diagonal line has one pixel in each row, therefore the line pixel count is $M$.

Lets denote the number of pixels inside the graph as $p$ and the pixel percentage as $P$.
Taking into account a graph utilizing performance improvements, the pixel percentage can be calculated with the following expression:
\[
  P = (p-M)/(M^2-M)*2*100
\]
Note that we subtract the diagonal line from both sides of the equation, then multiply everything by a factor of 2 to factor in that we are only dealing with half the plot data.
Finally we multiply by 100 to get the ratio in percentages.


\subsection{Calibrating the treshold parameter}
\label{sec:calibrating-threshold}
As previously mensioned, when generating a recurrence plot, a parameter $r$ determines a treshold for the maximum allowed distance between a pair of signal states.
Looking back at figure~\ref{fig:theory_sin} we can see that a higher $r$ value produces a more densly populated recurrence plot.

A recurrence plot with a low pixel percentage can be difficult to read as it lacks data.
Similarly, a plot too densely populated with pixels can have the same effect.
Usually a healthy percentage target is between 15 and 20 percent.
The algorithm does not provide an easy way to determine $r$ value.
A human can guess a treshold value, generate a plot, check the pixel percentage and adjust $r$.
This is to be repeated until desired pixel percentage is reached.

It is prefered to tackle such tasks programatically.
Lets denote $t$ as the target pixel percentage and $a$ as the allowed pixel percentage deviation.
We first define the minimum and maximum values for $r$.
Assuming we use the Maximum norm, we can deduce that $r_{min}=0$ and $r_{max}=max(y)$, where $y$ is array of input data.
A fair guess for $r$ could be calculated by multiplying subtracting the maximum and minimum treshold values and scaling by the pixel percentage target
\[r=(r_{max}-r_{min})*t/100\]
It is unlikely that the pixel percentage is estimated correctly, but it is a starting point.
A full programatic implementation of the algorithm is provided in appendix~\ref{app:pixel_calibration}.
Refering to it we can see that the current and previous value for $r$ and $P$ are stored.
Each iteration the sum of $r$ and $r_{last}$ is compared to $P$ and $P_{last}$.
This ratio is then scaled to the target pixel percentage $p$.
This is algorithm is repeated until a given pixel percentage target is reached.
Using this programatic solution can find $r$, where $P≈t$ in 2 to 3 iterations.
% Ideally a recurrence graph would show just enough details to 



% The values making up a signal state may not necessarily be purely consecutive. 

% A signal $y$ of length ${N+1}$ can be divided into $D$ - dimensional vectors and expressed as $\vv{x} \longrightarrow$





% Let us consider figure~\ref{fig:react_components}


% At first glance it is difficult to grasp how this algorithm can help identify the non-triviality of a signal.

% This algorithm is a of complexity ${O(N^2)}$, where ${N}$ is the length of the array. 


% A lot can be added to this extremely simplified version of the algorithm, but the complexity level stays the same.


% Let us consider 


% When trying to determine the non-triviality of a signal, a recurrence plot

% Depending on data origin, signal have varying lengths.


% \begin{figure}[!htb]
%   \minipage{0.32\textwidth}
%     \includegraphics[width=\linewidth]{assets/theory_graph_sin.png}
%     \caption{Generate sine wave data}\label{fig:awesome_image1}
%     \label{fig:theory_graph_sin}
%   \endminipage\hfill
%   \minipage{0.32\textwidth}
%     \includegraphics[width=\linewidth]{assets/theory_rp_sin_sm.png}
%     \caption{Recurrence plot D=1, d=1, r=0.0017}\label{fig:awesome_image2}
%     \label{fig:theory_graph_sin}
%   \endminipage\hfill
%   \minipage{0.32\textwidth}%
%     \includegraphics[width=\linewidth]{assets/theory_rp_sin_lg.png}
%     \caption{Recurrence plot D=1, d=1, r=0.6}\label{fig:awesome_image3}
%     \label{fig:theory_graph_sin}
%   \endminipage
% \end{figure}

% Signals can be observer all around us. 
% For example, measuring the time taken between a weight-driven
% pendulum clock's ticks produces a signal. It does not require 
% a great deal of effor to image how such a signal behaves.
% We would expect the clock's pendulum to swing back and forth,
% each time travelling a minutely shorter distance until the pendulum
% stops completely. Analysis of even a part of such a signal can help 
% us determine the pendulum's position far into future.


% Now consider a more complex siganl: the rates of a stock market.
% People have been analyzing this data for decades, grasping to 
% predict its future state.
% For the scope of this paper, we defined the term signal processing as
% \textit{the science of analyzing time-varying processes} \cite{lyons2004understanding}.


% In this thesis we analyzed the non-triviality of digital sygnals.
% Certain signals can be classified as simple (relatively trivial),
% like the aforementioned clock's pendulum.
% A more complex (non-trivial) signal would be the rates of a stock exchange.


% \section{Signal processing and Recurrence plot}
% \label{sec:motivation}
% \subsection{Signal processing}

% A signal is a function that conveys information about the behaviour of a system
% or attributes of some phenomenon \cite{priemer1990introductory}.
% For example, measuring the time taken between a weight-driven
% pendulum clock's ticks produces signal.
% In turn, for the scope of this paper, we defined the term signal processing as
% \textit{the science of analyzing time-varying processes} 
% \cite{lyons2004understanding}.
% By processing a signal we analyzed the non-triviality of a given signal.
% Analyzing a signal reveals that some signals 
% have properties that can be categorized.

% \subsection{Signal property categories}


% We have considered the following categories:
% \begin{enumerate}
%   \item Stationary and non stationary signals
%   \item 
% \end{enumerate}


% Signals have varying properties. Some consist of simple repetitions while others
% have no apparent patterns.
% For example, measuring the time taken between a weight-driven
% pendulum clock's ticks produces a relatively simple (trivial) signal.

\section{Web application development}
This project is aimed at creating a web application allowing one to interact with the recurrence plot algorithm in a user friendly manner.
The project offers a feature of classifying data based on the generated plot using convolutional neural networks.
This is an effort to further spread the popularity of this algorithm and help users intuitively grasp how it behaves.


\subsection{Analysis of analogous tools}
As of the date of publishing, only one tool was located capable
of generating a recurrence plot online \cite{recurrence_plot_tk}.
There are multiple implementations of the recurrence plot in Python as well as other
languages, but none offer the ability to classify data based on the generated image.

It is noteworthy, that the aforementioned implementations require at least a minimal undertanding of software programming, a computing machine and specific software to compile and run the code.
This is laborious and is not likely to attract new users to experiment with algorithm.
Based on these factors, a decision was made to create a web based application that requires
as little user knowledge to get started with the algorithm as possible.


%=================================Architecture
\subsection{Architecture}
This project consists of three microservices.
Microservices are small autonomous services deployed independently, with a single and clearly defined purpose \cite{krause2015microservices}. This design approach was chosen due to the flexibility and scalability associated with the architecture. %%%% %%Probably useless sentence
The nature of microservices allows one to easily test, modify or out right replace each one of the components giving more freedom to the developer.
The project ecosystem consists of the following microservices:
\begin{enumerate}
  \item Front end web application
  \item Back end for the web application
  \item Python web server for plotting operations
\end{enumerate}

Communication between microservices is performed via HTTP requests. In general, a query with JSON body is sent to a service and a JSON response along side an image attachment is returned.
Figure~\ref{fig:architecture_diagram} illustrates the microservice architecture of the project and data flow among services.

\begin{figure}[h]
  \centering
  {\includegraphics[height=8cm]{assets/architecture_diagram.png}}
  \caption{Microservice architecture structure}
  \label{fig:architecture_diagram}
\end{figure}


%=================================Project structure
\subsubsection{Project structure}
The project is structured so that each microservice resides in an independent directory:
\begin{itemize}
  \item app/
        \begin{itemize}
          \item src/
                \begin{itemize}
                  \item components/
                \end{itemize}
          \item public/
        \end{itemize}
  \item server/
        \begin{itemize}
          \item db/
          \item public/
          \item utils/
        \end{itemize}
  \item plotter/
        \begin{itemize}
          \item jupyter/
        \end{itemize}
\end{itemize}

As the name suggests - \code{/app/} directory contains the front end ReactJS application.
The NodeJS express\cite{express} server resides inside the \code{/server/} directory.
Meanwhile, \code{/plotter/} contains all of the Python source code. That includes the flask \cite{flask} web server, the recurrence plot module, jupyter notebooks for convolutional neural network model development and scripts for model training data generation.


%=================================Project workflow
\subsubsection{Project workflow}
We will now cover an example workflow of the application as per figure~\ref{fig:architecture_diagram}.

When first opening the app, a request is sent to the back end to fetch a list of existing plot data.
The user selects an entry from the list and fills in remaining parameters for generating a recurrence plot.
A request with select data ID is sent to the back end microservice.
The back end service fetches data from the database and forwards it to the plotting service.
The plotting service generates an image, then runs the image through a convolutional neural network to get classification data.
Finally, the plotting service sends the image along with classification data back to the back end service, which in turn forwards it to the front end service.
The front end service displays the image and classification data.


%=================================Microservices
\subsection{Microservices}
The tools used for microservice development were largely open-sourced and relatively modern.
Front end and Back end services were written in javascript
based environments - React JS and Node JS respectively.
These choices were made due to the widespread use of javascript in modern web application development providing a large pool of open-sourced libraries and tools.

On the other hand python was the tool used to develop the plotting service. It is known to perform better on data handling and machine learning than javascript alternatives \cite{javascript_vs_python_ml}.
Both Python and Node JS have certain strengths and thus have appropriate community driven libraries and modules to reinforce their leverages in appropriate operations.


%=================================Front end microservice
\subsubsection{Front end microservice}
The front end service is developed using React - A JavaScript library for building user interfaces \cite{react_home}.
SASS is used for styling the apllication due to the intuitive syntax it provides \cite{sass}.
The microservice utilizes the Node Package Manager \cite{npm}.
From the NPM registry, two open sourced libraries are used:
\begin{itemize}
  \item node-fetch - A module that brings window.fetch to Node.js \cite{node-fetch}.
  \item query-string - a tool for building HTTP query string \cite{query-string}.
\end{itemize}
These libraries were used to facilitate communication via HTTP requests with the back end server.

Following the best practices of React development, the app is broken down into reuseable components.
Figure~\ref{fig:react_component_structure} indicates the application structure denoting components with the standard JSX component notation
\code{<component />}. We will be using this notation to refeter to JSX components.
\begin{figure}[h]
  \centering
  {\includegraphics[height=6cm]{assets/react_component_structure.png}}
  \caption{React app component structure}
  \label{fig:react_component_structure}
\end{figure}

Figure~\ref{fig:react_component_structure} indicates that a root \code{<App />} component wraps the whole application.
Initially, only the \code{<Header />}, \code{<Selector />} and \code{<Loader />} components are visible to the user.
The \code{<Selector />} component sends an HTTP GET request to the backend service to retrieve a list of available plot data.
This list is displayed inside the \code{<Selector />} for the user to pick from.
A user must select a data entry and may add optional plotting parameters.
Submitting the \code{<Selector />} form sends an HTTP GET request to the back end service.
The backend service returns a JSON with the location of the generated recurrence plot image and additional parameters.
After handling the server response - the \code{<Loader />} component is replaced by the \code{<Image />}.
During any further plot requests, the \code{<Image />} is briefly replaced by the \code{<Loader />} component to indicate that a request is being processed.


%=================================Back end microservice
\subsubsection{Back end microservice}
The backend microservice also utilizes libraries provided by the Node Package Manager.
The service runs on an Node JS express server \cite{express}.
The server handles all requests from the front end service.
Server endpoints cover the following operations:
\begin{itemize}
  \item CRUD operations for plot data stored inside the MongoDB database
  \item Requests to generate a recurrence plot using the plotting service
\end{itemize}
The express server communicates with the database server by making use of an open sourced MongoDB object modeling library - mongoose \cite{mongoose}.
The service itself does not generate any plot data, but merely acts as an intermediary between the front end service, the MongoDB database and the plotting service.


%=================================Plotter microservice
\subsubsection{Plotter microservice}
\label{sec:plotter_microservice}
The plotter microservice handles requests to generate and classify recurrence plots.
The service utilizes numpy\cite{numpy}, scipy\cite{scipy} and matplotlib\cite{matplotlib} open sourced python libraries.

The service consists of 3 main parts:
\begin{enumerate}
  \item Flask - a python web framework
  \item Recurrence plot module
  \item Data classification model
\end{enumerate}
The flask service handles HTTP requests with JSON data as input.
The service processes the input and generates an image using the recurrence plot module.
Image is passed through the convolutional neural network to get the image classification.
An HTTP response is then sent containing the classification data and the generated image as an attachment.


%=================================Recurrence plot module
\subsection{Recurrence plot module}
\label{sec:recurrence_plot_module}
The recurrence plot module is a Python implementation of the algorithm used to generate a recurrence plot.
The module creates a \code{RecurrencePlot} object.
The object takes in several parameters as input allowing one to customize the following features of the generated plot:
\begin{itemize}
  \item D - signal dimension
  \item d - signal delay
  \item compare\_mode - evaluation metric: euclidean and maximum
  \item target - Prefered pixel percentage of the recurrence plot
  \item deviation - allowed deviation for final pixel percentage
\end{itemize}
As output the module returns the name of the asset in the local storage.
The object can also be manipulated to retrieve various other metrics about the recurrence plot.
The module implements all of the best practices described in sections~\ref{sec:comparing-signal-states} -~\ref{sec:calibrating-threshold}.


%=================================Data classification model
\section{Data classification model}
A recurrence plot reveals certain information about the singal.
After some practice a human can identify whether a given signal exhibits signs of periodity and / or stationarity, has a trend or seems to be random in nature.
The goal of this model is to determine some the aforementioned characteristics of a signal by analyzing the reucrrence plot generated by it.


%=================================Generating training data
\subsection{Tools and libraries}
The convolutional neural network along with assets was developed using the python programming language. Libraries for asset generation, image preprocessing and the training of CNN are mostly open sourced. They are as follows: Numpy~\cite{numpy}, TensorFlow~\cite{tensorflow}, Keras~\cite{keras}, scikit-learn~\cite{scikit-learn} and matplotlib~\cite{matplotlib}.


%=================================Generating training data
\subsubsection{Hardware specifications}
\label{sec:hardware}
Machine learning is a resource intensive task.
TensorFlow supports both: the Central Processing Unit and Graphics Processing Unit for training neural networks.
For this project, GPU accellerated learning was used.
The GPU device used: GTX 1070 Ti with 8 Gigabytes of on-board memory.


%=================================Generating training data
\subsection{Generating training data}
It is common knowledge that one requires data to train a convolutional neural network.
The accuracy of a data model heavily weighs on the quality of training data and labeling.
After a brief search for publicly available, labeled and categorized data that is suitable for training a recurrence plot categorising model, a decision was made for this data to be generated synthetically.


%=================================Training data methodologies
\subsubsection{Training data methodologies}
All of the following signals and their graphs are generated by utilizing
the aforementioned libraries and the recurrence plot module.
For every signal a complementary graph image is generated to help visualize the data which is depicted in a given recurrence plot.
Due to the module flexibility every chaotic and periodic asset had randomised values for D - Dimension and d - delay.
In addition, most aspects of each graph had a randomised flaoting point number be added or subtracter.
This aided in generating a more diverse set of training assets.
The number of assets chosen was arbitraty - 1000 sygnals for each training label.
That amounts to a total of 3000 recurrence plot images used for training the CNN.
The source code for generating assets and associated graphs is inside the \code{/plotter/generate-cnn-assets.py} file.


%=================================Choosing classification features
\subsubsection{Choosing classification features}
Before generating the data it is important to recognize what the convolutional neural network is expected to learn from it.
The \emph{what can it learn?} aspect of a CNN is mostly limited by the labeled data we can provide.
A choice was made to classify plot images into one of the three groups:
\begin{itemize}
  \item Plotted signal is chaotic
  \item Plotted signal has a trend
  \item Plotted signal has is periodic
\end{itemize}
We will explore the reasoning of this decision by exploring the limitations of generating labeled signals.


%=================================Chaotic signal
\subsubsection{Chaotic signal}
\begin{figure}
  \centering
  \subfloat[\centering Chaotic signal]{{\includegraphics[height=5.5cm]{assets/chaos_graph.png} }}
  \qquad
  \subfloat[\centering Recurrence plot. Pixel target=17.5\%, D=2, d=1]{{\includegraphics[height=5cm]{assets/chaos_rp.png} }}
  \caption{Chaotic signal and recurrence plot generated by it}
  \label{fig:generated_chaotic}
\end{figure}
A relatively simple signal to identify is a chaotic signal.
Chaotic, means it has no distinguishable pattern - random.
This signal can be generated rather easily - by calling a random number generator for each entry in the signal.
It is also advantageous, that chaotic signal does not trigger any other feature attribute except for stationarity.
A chaotic signal tends to have a high level of stationary meaning it is dispersed fairly evenly across the recurrence plot.
Figure~\ref{fig:generated_chaotic} displays a signal (a) and the generated recurrence plot (b) from the training set.
This signal is labeled as chaotic and is one of the signals used for training the convolutional neural network.


%=================================Periodic signal
\subsubsection{Periodic signal}
\begin{figure}
  \centering
  \subfloat[\centering Sine wave signal]{{\includegraphics[height=5.5cm]{assets/period_graph_sin.png} }}
  \qquad
  \subfloat[\centering Recurrence plot. Pixel target=17.5\%, D=3, d=2]{{\includegraphics[height=5cm]{assets/period_rp_sin.png} }}
  \caption{Periodic sine wave form signal and recurrence plot generated by it}
  \label{fig:generated_periodic_sin}
\end{figure}
For a human, identifying a signal with a periodic characteristic is not too strenuous either.
Unfortunately we cannot consider the periodicity of a signal without considering the stationarity of it.
Stationarity is generally observed by the homogeneity of a signal.
In layman terms - how evenly the pixels are spread across the recurrence plot.
Looking back at figure~\ref{fig:generated_chaotic} we can see that a chaotic signal is highly stationary as the pixels are spread fairly evenly.
Figure~\ref{fig:generated_periodic_sin} illustrates a signal (a) from the periodic training set and the recurrence plot (b) that is generated from it.
We can see that this siganl forms a grid pattern.
The pattern stretches across the whole image therefore this signal is also stationary.
It would be difficult to generate periodic data that is not stationary, but the same applies to chaotic data.
This is the reason why stationarity is not one of the attributes measured by the model.
Determining the level of periodicity is beyond the scope of this particular neural netowrk.

A periodic signal wave can have difference forms.
The signal in figure~\ref{fig:generated_periodic_sin} is generated from a sine wave.
To provide the model with more diverse training data - two additional distinct wave functions were used to generate the training data.
Figure~\ref{fig:generated_periodic_square} illustrates a signal with a square wave. See the signal wave (a) on the left and generated recurrence plot on the right (b).
\begin{figure}
  \centering
  \subfloat[\centering Square wave signal]{{\includegraphics[height=5.5cm]{assets/period_graph_square.png} }}
  \qquad
  \subfloat[\centering Recurrence plot. Pixel target=17.5\%, D=4, d=2]{{\includegraphics[height=5cm]{assets/period_rp_square.png} }}
  \caption{Periodic square wave form signal and recurrence plot generated by it}
  \label{fig:generated_periodic_square}
\end{figure}
The final waveform to be used for periodic images is the sawtooth waveform.
Figure~\ref{fig:generated_periodic_sawtooth} illustrates the wave signal (a) and the recurrence plot generated (b) using it.

\begin{figure}
  \centering
  \subfloat[\centering Sawtooth wave signal]{{\includegraphics[height=5.5cm]{assets/period_graph_sawtooth.png} }}
  \qquad
  \subfloat[\centering Recurrence plot. Pixel target=17.5\%, D=4, d=2]{{\includegraphics[height=5cm]{assets/period_rp_sawtooth.png} }}
  \caption{Periodic sawtooth wave form signal and recurrence plot generated by it}
  \label{fig:generated_periodic_sawtooth}
\end{figure}


%=================================Signal with a trend
\subsubsection{Signal with a trend}
A trend signal is quite distinguishable by it's tendency to be less stationary than the previous two.
Recurrence plot of a non synthetic trend signal appears to center aruond the diagonal symetry line and tends to have an increasing width towards either side of the image.
Figure~\ref{fig:generated_trend} illustrates an example trend signal (a) and the recurrence plot generated using it (b).
This is one of the labeled samples used in training the convolutional neural netowrk.

These signals are generated by using a randomly generated data starting point. Then generating an integer within a given range to simulate increasing or decreasing data.
Finally slightly increasing the average signal value by a flat value multiplied by an exponent.
This allows synthetic trend data to either increase linearly or exponentially.
Looking closely to figure~\ref{fig:generated_trend} image on the left we can see that the trend data exhibits an exponentially increasing in values.
The exponent is picked to be small so that the synthetic signal appears more
natural.

\begin{figure}
  \centering
  \subfloat[\centering Trend signal]{{\includegraphics[height=5.5cm]{assets/trend_graph.png} }}
  \qquad
  \subfloat[\centering Recurrence plot. Pixel target=17.5\%, D=4, d=2]{{\includegraphics[height=5cm]{assets/trend_rp.png} }}
  \caption{Trend signal and recurrence plot generated by it}
  \label{fig:generated_trend}
\end{figure}


%=================================Data preprocessing
\subsection{Data preprocessing}
Assets used for training a model need to be properly prepared before they can be used by the convolutional neural network.
But first, it is vital to determine the form of the CNN input data.
There are two obvious ways for tackling this problem.

One way is for the signal to be passed as a two dimensional array of binary data.
At the corresponding pixel location the array of binary data would containing 0 if a pixel is white and a 1 otherwise.
The array data size could further be reduced if only one half of the symetrical image was taken.

Another way of dealing with this is by using the whole image as an input.
An andantage of this approach is that the model would be less dependent on the recurrence plot implementation and would be easier to use by a third party.
A downside to this approach is that training this model would require more computing power. It was decided to use the whole image as an input.

The complete pool of assets is divided into istributed into three groups:
\begin{itemize}
  \item Training data - used for the training of the model. This group contains 85\% of all training assets.
  \item Validation data - used to validate the model accuracy after each training epoch completes. This group contains 10\% of all training assets.
  \item Testing data - used for manual testing of the final model. This group contains 5\% of all training assets.
\end{itemize}
Images in each group are preprocessed using the vgg16 preprocessor~\cite{brusilovsky:simonyan2014very}, labeled and divided into
batches of 10.
Utilizing the vgg16 preprocessor, image is scaled down to the size of 224 by 224 pixels.
This is implemented in order to reduce the number of parameters in the CNN.


%=================================Data preprocessing
\begin{figure}[h]
  \centering
  {\includegraphics[height=7cm]{assets/cnn_layers.png}}
  \caption{Convolutional neural network layer structure}
  \label{fig:cnn_layers}
\end{figure}


%=================================Convolutional neural network
\subsection{Convolutional neural network}
A convolutional neural network is a type of artificial neural network that has been successfully applied in computer vision tasks~\cite{recent_advances_in_cnn}.
Typically, a CNN consists of convolutional pooling and traditional fully connected layers.
An important aspect of a CNN, is to obtain abstract features when input propagates toward the deeper layers~\cite{understanding_cnn}.
This is exactly what we expect the CNN to pick up on.
For example, we expect a CNN to recognize grid patterns in figure~\ref{fig:generated_periodic_sin} and associate them with a periodic attribute.

To achieve this goal the CNN is inspired by the famous vgg16 model~\cite{brusilovsky:simonyan2014very}.
The model proposed earlier is excellent for spacial objects recognitions.
Unfortunately it did not achieve desired results for our task.
The CNN would perform well on the training samples, but poorly when faced with novel images.
This indicates an overfitting problem.
Overfitting is a fundamental issue in supervised machine learning which prevents a neural network from generalizing the models to perform well on training data, as well as unseen testing sets~\cite{overfitting}.
It is usually caused by lack of training data or a neural network with too many parameters.

A common and effective way to combat overfitting is the introduction of dropout layers.
A dropout layers randomly sets input units to 0 with a given frequency rate at each step during training time~\cite{dropout}.
Adding a dropout layer with the frequency rate of 25\% after every pooling solved the overfitting issue.
This is illustrated in figure~\ref{fig:cnn_layers}.


%=================================CNN layer structure
\subsubsection{CNN layers structure}
In total, a given input goes through 15 layers.
Using the Keras Sequential class, layers are grouped into a linear stack~\cite{sequential}.
The CNN has four pairs of convolutional layers illustrated as black rectangles in figure~\ref{fig:cnn_layers}.
Excluding the first two layers, each pair of convolutional layers has max pooling layer marked before them and a dropout layer after them.
In figure~\ref{fig:cnn_layers}, the max pooling and dropout layers are depicted in red and blue respectively.
A fully connected layer with the softmax activation acts as the output layer.


%=================================CNN layer structure
\subsubsection{Training and testing the CNN}

\begin{figure}[h]
  \centering
  {\includegraphics[height=7cm]{assets/confusion_matrix.png}}
  \caption{Confusion matrix for predicting test data, n=150}
  \label{fig:confusion_matrix}
\end{figure}

The Keras Sequential model is trained by compiling it and invoking the fit function.
The model was compiled using the following parameters: Adam - optimizer function of choice, learning rate - 0.001, objective function - crossentropy objective, metrics - accuracy.

Model was trained in 10 epochs, each taking about 27 seconds to train, running on the aforementioned GPU accellerated hardware~\ref{sec:hardware}.

After 7 our of 10 epochs the model seems to be performing at a 100\% accuracy.
Testing the model with novel data yields the same results.
Figure~\ref{fig:confusion_matrix} confusion matrix illustrates the results of predicting the charactestics of recurrence plot data before unseen to the model. Looking at the first column and first row of the matrix, we can identify that 50 out of 50 images were classified as periodic. The same apllies for trending and chaotic samples. This indicates that the model performs very well on this type of data.



% Black rectangles depict the convolutional layers using the \textbf{ReLU}~\cite{relu} activation function.

% This solution offers higher efficiency as the model would be dealing with significantly less data.

% \begin{figure}[h]
%   \centering
%   {\includegraphics[height=8cm]{assets/architecture_diagram.png}}
%   \caption{Microservice architecture structure}
%   \label{fig:architecture_diagram}
% \end{figure}

% Identify what are the attributes 

% An ideal training dataset would have a sizeable amount CNN
% In order for a 
% This decision was based purely on the ability to generate data that is labeled accordingly.


% \subsection{Model limitations}
%We will go more in depth about each microservice in later sections.


% For the scope of this paper, we defined the term signal 
% processing as \textit{the science of analyzing time-varying 
% processes} \cite{lyons2004understanding}.




% \subsection{Signal classification}
% Signals have several classes. For the scope of this paper we considered
% the classes \cite{lathi1998signal}:
% \begin{enumerate}
%   \item Stationary and non-stationary signals
%   \item 
%   \item Periodic, quasi periodic and aperiodic signals 


% \end{enumerate}






% Some signals are inherently simple such as the time taken
% a falling object or

% \begin{lstlisting}
%   sygnalStates = []

%   # Generate data pairs, tripplets, quadruplets... D - plets
%   for i in range(0, self.M):
%       state = []

%       for j in range(0, self.D):
%           state.append(self.data[i+(j*self.d)])

%       sygnalStates.append(state)
% \end{lstlisting}



% \newpage
% \section{Pirmasis skyrius}
% \label{sec:motivation}

% asa \cite{recurrence-plot}



% \subsection{Pirmojo skyriaus poskyris}
% \label{sec:example}
% Pateikiamas \ref{sec:example} poskyrio tekstas. Vienas iš šaltinių~\cite{KTZ}. Visas ~\cite{KTV} turinys priklauso \ref{sec:motivation} skyriui.

% \subsubsection{Pirmojo skyriaus pirmo poskyrio poskyris}
% \label{sec:data}
% Pateikiamas trečio lygio poskyrio tekstas.

% \begin{equation}
%   x = \sum_{i=1}^N m_i
% \end{equation}

% \begin{table}[!ht]\centering
%   \caption{Lentelė ... }
%   \label{tabl:table}
%   \begin{tabular}{l|r|}
%     test & test \\ \hline
%     test & test \\
%   \end{tabular}
% \end{table}

% Sprendimas pristatomas \ref{alg:1} algoritme, o įgyvendinimas -- \ref{abc} išeities kode.

% \begin{algorithm}\caption{Algoritmas uždavinio sprendimui}
%   \label{alg:1}
%   \begin{algorithmic}
%     \REQUIRE
%     \ENSURE
%     \STATE a \AND b
%   \end{algorithmic}


% \end{algorithm}



%Conclusions section
\newpage
\sectionWithoutNumber{\keyWordConclusions}{conclu}
\input{conclusions.tex}

%ateities darbų gairės, planas/next steps of the work
% \sectionWithoutNumber{Ateities tyrimų planas}{future}{Pristatomi ateities darbai ir/ar jų planas, gairės tolimesniems darbams....}


%file literatureSources.bib
\referenceSources{literatureSources}


%% this part is optional
\newpage
\begin{appendices}
  The paper contains appendicy \ref{app:pixel_calibration}. It displays a programatic solution to calibrating pixel percentage implemented in Python programming language.
  \newpage
  \section{Callibrating recurrence plot threshold \code{r}}
  \begin{lstlisting}[caption={Pixel percentage calibration}]
def calibrate_r(input_data, pixel_percentage_target, allowerd_deviation):
  # Initialize variables
  r = min(input_data)
  pixel_percentage = 0
  r_last = max(input_data) - min(input_data)
  pixel_percentage_last = 100

  # Loop until calibrated
  while (abs(pixel_percentage-pixel_percentage_target) > allowed_deviation):
    # Compare the sum of current and previous R
    # to the sum of current and previous pixel percentages
    # Then scale R value based on pixel percentage target

    r = (r+r_last)/(pixel_percentage+pixel_percentage_last)*pixel_percentage_target
    
    # Calculate recurrences
    calculate_recurrences()

    # Update last pixel percentage and r
    pixel_percentage_last = pixel_percentage
    r_last = r
  return r
  \end{lstlisting}
  \label{app:pixel_calibration}

\end{appendices}


\end{document}

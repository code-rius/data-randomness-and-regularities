{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv1D, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import timeit\n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "from recurrence_plot import RecurrencePlot as rp\n",
    "#warnings.simplefilter(action='ignore',category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for compatable GPU (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaos_labels = np.array([1,0,0])\n",
    "period_labels = np.array([0,1,0])\n",
    "trend_labels = np.array([0,0,1])\n",
    "\n",
    "chaos_path = 'rp-data/chaos'\n",
    "period_path = 'rp-data/period'\n",
    "trend_path = 'rp-data/trend'\n",
    "\n",
    "train_data_path = 'rp-data/train_data.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform images into pixel arrays and save them as a .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  9.395362567999996 \tImages processed:  50\n",
      "Time taken:  18.778466397999978 \tImages processed:  100\n",
      "Time taken:  28.339144472999976 \tImages processed:  150\n",
      "Time taken:  38.23711120399997 \tImages processed:  200\n",
      "Time taken:  47.62365780099998 \tImages processed:  250\n",
      "Time taken:  56.951241323999966 \tImages processed:  300\n",
      "Time taken:  66.25916217700001 \tImages processed:  350\n",
      "Time taken:  75.91146799999996 \tImages processed:  400\n",
      "Time taken:  85.45756617 \tImages processed:  450\n",
      "Time taken:  95.09342536399998 \tImages processed:  500\n",
      "Time taken:  104.61276306799999 \tImages processed:  550\n",
      "Time taken:  114.139485907 \tImages processed:  600\n",
      "Time taken:  123.42727572399997 \tImages processed:  650\n",
      "Time taken:  132.91935320699997 \tImages processed:  700\n",
      "Time taken:  142.330634423 \tImages processed:  750\n",
      "Time taken:  151.61234488000002 \tImages processed:  800\n",
      "Time taken:  160.893504162 \tImages processed:  850\n",
      "Time taken:  170.76986989499994 \tImages processed:  900\n",
      "Time taken:  180.26621464200002 \tImages processed:  950\n",
      "Time taken:  189.786948823 \tImages processed:  1000\n",
      "Total time taken:  189.78708366499995\n",
      "Time taken:  9.456310515999917 \tImages processed:  50\n",
      "Time taken:  19.00787074199991 \tImages processed:  100\n",
      "Time taken:  28.515094863999934 \tImages processed:  150\n",
      "Time taken:  38.00138808499992 \tImages processed:  200\n",
      "Time taken:  47.53673860799995 \tImages processed:  250\n",
      "Time taken:  56.82691378300001 \tImages processed:  300\n",
      "Time taken:  66.07011498199995 \tImages processed:  350\n",
      "Time taken:  75.21151808899992 \tImages processed:  400\n",
      "Time taken:  84.58884506599998 \tImages processed:  450\n",
      "Time taken:  94.19482507099997 \tImages processed:  500\n",
      "Time taken:  103.81645707299992 \tImages processed:  550\n",
      "Time taken:  113.4373126019999 \tImages processed:  600\n",
      "Time taken:  122.91586265000001 \tImages processed:  650\n",
      "Time taken:  132.46396233099995 \tImages processed:  700\n",
      "Time taken:  141.8081495419999 \tImages processed:  750\n",
      "Time taken:  151.75793283199994 \tImages processed:  800\n",
      "Time taken:  161.331223604 \tImages processed:  850\n",
      "Time taken:  170.670729381 \tImages processed:  900\n",
      "Time taken:  179.86332709299995 \tImages processed:  950\n",
      "Time taken:  189.07351917699998 \tImages processed:  1000\n",
      "Total time taken:  189.45431692499994\n",
      "Time taken:  9.667373299000019 \tImages processed:  50\n",
      "Time taken:  19.457318504 \tImages processed:  100\n",
      "Time taken:  29.201777247999985 \tImages processed:  150\n",
      "Time taken:  38.853978678999965 \tImages processed:  200\n",
      "Time taken:  48.69588294899995 \tImages processed:  250\n",
      "Time taken:  58.701517741999965 \tImages processed:  300\n",
      "Time taken:  68.67704297399996 \tImages processed:  350\n",
      "Time taken:  78.52322661100004 \tImages processed:  400\n",
      "Time taken:  88.63885568599994 \tImages processed:  450\n",
      "Time taken:  98.75740500799998 \tImages processed:  500\n",
      "Time taken:  108.15554172999998 \tImages processed:  550\n",
      "Time taken:  118.32017350199999 \tImages processed:  600\n",
      "Time taken:  128.59242151800004 \tImages processed:  650\n",
      "Time taken:  138.609859303 \tImages processed:  700\n",
      "Time taken:  148.60283284900004 \tImages processed:  750\n",
      "Time taken:  159.33080106399996 \tImages processed:  800\n",
      "Time taken:  169.14271534499994 \tImages processed:  850\n",
      "Time taken:  179.24813331899998 \tImages processed:  900\n",
      "Time taken:  189.12490038099997 \tImages processed:  950\n",
      "Time taken:  199.04085733499994 \tImages processed:  1000\n",
      "Total time taken:  199.04124363300002\n"
     ]
    }
   ],
   "source": [
    "def binarize_image_array(pixels_array):\n",
    "    graph_list = []\n",
    "    triangle_width = len(pixels_array) - 1\n",
    "\n",
    "    for i in range(triangle_width):\n",
    "        for j in range(triangle_width - i):\n",
    "            pixel = 1\n",
    "            if (pixels_array[i][j][0] == np.float32(255)):\n",
    "                pixel = 0\n",
    "             \n",
    "            graph_list.append(pixel)\n",
    "            \n",
    "    return graph_list\n",
    "    \n",
    "\n",
    "def populate_train_data(image_dir, train_label):\n",
    "    counter = 0\n",
    "    t_start = timeit.default_timer()\n",
    "    t_samples, t_labels = [], []\n",
    "    \n",
    "    for file in os.listdir(image_dir):\n",
    "        filename = os.fsdecode(file)\n",
    "        \n",
    "        if filename.endswith(\".png\"):\n",
    "            counter += 1\n",
    "            \n",
    "            img_path = os.path.join(image_dir, filename)\n",
    "            img = load_img(img_path)\n",
    "            \n",
    "            pixels_array = img_to_array(img)\n",
    "            pixels_array_binarized = binarize_image_array(pixels_array)\n",
    "            \n",
    "            t_samples.append(pixels_array_binarized)\n",
    "            t_labels.append(train_label)\n",
    "            \n",
    "            if (counter % 50 == 0):\n",
    "                print(\"Time taken: \", timeit.default_timer()-t_start\\\n",
    "                     ,'\\tImages processed: ', counter)\n",
    "\n",
    "    t_end = timeit.default_timer()\n",
    "    print(\"Total time taken: \", t_end - t_start)\n",
    "    \n",
    "    t_samples = np.array(t_samples, dtype=np.uint8)\n",
    "    t_labels = np.array(t_labels, dtype=np.uint8)\n",
    "    \n",
    "    return [t_samples, t_labels]\n",
    "\n",
    "chaos_data = populate_train_data(chaos_path, chaos_labels)\n",
    "period_data = populate_train_data(period_path, period_labels)\n",
    "trend_data = populate_train_data(trend_path, trend_labels)\n",
    "\n",
    "train_samples = np.concatenate((chaos_data[0], period_data[0], trend_data[0]), axis=0)\n",
    "train_labels = np.concatenate((chaos_data[1], period_data[1], trend_data[1]))\n",
    "\n",
    "np.savez(train_data_path, samples=train_samples, labels=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train data into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(train_data_path)\n",
    "train_samples = train_data['samples']\n",
    "train_labels = train_data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign data into \"train\", \"valid\" and \"test\" groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258840\n"
     ]
    }
   ],
   "source": [
    "print(len(train_samples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dropout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1446ce40bdfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dropout' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(258840,1)),\n",
    "    #Dense(units=64, input_shape=(258840,), activation='relu'),\n",
    "    Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
    "    Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
    "    MaxPooling1D(pool_size=1),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(units=3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 1, 64)             16565824  \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1, 64)             4160      \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 1, 64)             4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 16,580,947\n",
      "Trainable params: 16,580,947\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_samples, y=train_labels, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "#              loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
